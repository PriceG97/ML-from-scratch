# ML From Scratch

This repository contains a collection of core machine learning components implemented **from scratch** in Python using only **NumPy** â€” without relying on libraries like `scikit-learn`, `Keras`, `TensorFlow`, or `PyTorch`.

## ğŸ“¦ What's Included

- **ğŸ“Š Metrics**: Custom implementations of common evaluation metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and others.
- **ğŸ“ Feature Scaling**: Functions to standardise and normalise features (e.g., StandardScaler, MinMaxScaler).
- **ğŸ”€ Data Splitting**: A `train_cv_test_split` utility to divide your dataset into training, cross-validation, and test sets with configurable ratios and random shuffling.
- **ğŸ“ˆ Linear Regression**: Full implementation of a linear regression model trained using gradient descent, including:
  - Weight and bias updates
  - Configurable learning rate and number of epochs
  - Prediction and loss calculation

## ğŸš€ Purpose of This Project

The goal of this project is to **demonstrate a deep understanding of how machine learning models work internally**, without relying on high-level frameworks.

By rebuilding models from scratch, I aim to reinforce:
- Mathematical foundations behind ML algorithms
- Manual implementation of gradient descent and loss functions
- Practical experience structuring a machine learning library

This project also serves as a portfolio piece to show my technical depth and problem-solving ability.

## ğŸ› ï¸ Coming Soon

This is just the beginning. Future additions will include:
- **Classification models** (e.g., logistic regression, k-NN)
- **Neural networks**
- **Regularisation techniques**
- **Model selection utilities**
- **Visualisation tools**
- And more...

## âš™ï¸ Requirements

- Python
- NumPy
