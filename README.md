# ML From Scratch

This repository contains a collection of core machine learning components implemented **from scratch** in Python using only **NumPy** — without relying on libraries like `scikit-learn`, `Keras`, `TensorFlow`, or `PyTorch`.

## 📦 What's Included

- **📊 Metrics**: Custom implementations of common evaluation metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and others.
- **📐 Feature Scaling**: Functions to standardise and normalise features (e.g., StandardScaler, MinMaxScaler).
- **🔀 Data Splitting**: A `train_cv_test_split` utility to divide your dataset into training, cross-validation, and test sets with configurable ratios and random shuffling.
- **📈 Linear Regression**: Full implementation of a linear regression model trained using gradient descent, including:
  - Weight and bias updates
  - Configurable learning rate and number of epochs
  - Prediction and loss calculation

## 🚀 Purpose of This Project

The goal of this project is to **demonstrate a deep understanding of how machine learning models work internally**, without relying on high-level frameworks.

By rebuilding models from scratch, I aim to reinforce:
- Mathematical foundations behind ML algorithms
- Manual implementation of gradient descent and loss functions
- Practical experience structuring a machine learning library

This project also serves as a portfolio piece to show my technical depth and problem-solving ability.

## 🛠️ Coming Soon

This is just the beginning. Future additions will include:
- **Classification models** (e.g., logistic regression, k-NN)
- **Neural networks**
- **Regularisation techniques**
- **Model selection utilities**
- **Visualisation tools**
- And more...

## ⚙️ Requirements

- Python
- NumPy
